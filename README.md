# ğŸ“š Multi-Label Text Classification for Academic Papers

![Python](https://img.shields.io/badge/Python-3.8+-blue)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.0+-orange)
![LightGBM](https://img.shields.io/badge/LightGBM-3.3+-yellow)
![Transformers](https://img.shields.io/badge/Sentence%20Transformers-2.2+-brightgreen)

This project implements a multi-label classification system to categorize academic papers into three domains: Information Theory, Computational Linguistics, and Computer Vision.

## ğŸš€ Key Features

- **Advanced Text Preprocessing**
  - Custom cleaning pipeline for academic text
  - Stopword removal and stemming
  - Handling of special characters and formatting

- **Multi-Label Classification**
  - Comparative analysis of KNN, Random Forest, and LightGBM
  - Sentence Transformers for text embeddings
  - Parallel processing for large datasets

- **High Performance**
  - Achieved **97% F1-score** for Information Theory classification
  - **95% accuracy** on Computational Linguistics
  - **93% balanced accuracy** for Computer Vision

## ğŸ“Š Model Performance Summary

| Model               | Information Theory (F1) | Comp. Linguistics (F1) | Computer Vision (F1) |
|---------------------|-------------------------|------------------------|----------------------|
| KNN                 | 0.95                   | 0.90                  | 0.94                |
| Random Forest       | 0.87                   | 0.77                  | 0.91                |
| **LightGBM**        | **0.94**               | **0.90**              | **0.93**            |

## ğŸ› ï¸ Technical Implementation

### Data Preprocessing


### **Sentence Embeddings**
Initialize Sentence Transformer
model = SentenceTransformer("all-MiniLM-L6-v2")
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model.to(device)

# Batch processing for large datasets
def encode_batch(texts, batch_size=128):
    return model.encode(texts, show_progress_bar=False, device=device)


multi-label-paper-classification/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Original datasets
â”‚   â””â”€â”€ processed/            # Cleaned data
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ trained_models/       # Saved model files
â”‚   â””â”€â”€ embeddings/           # Precomputed embeddings
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ EDA.ipynb             # Exploratory analysis
â”‚   â””â”€â”€ Modeling.ipynb        # Classification experiments
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocessing.py      # Text cleaning
â”‚   â””â”€â”€ train.py             # Model training
â””â”€â”€ README.md
